{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oy7yFTpH7OBw"
   },
   "source": [
    "### Colab Notebook Configuration \n",
    "If running in a Colab Notebook, these next few cells get the local environment configured. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bEzf42Lrewzp"
   },
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "# wget -q https://www-us.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
    "# tar -xzf spark-2.4.5-bin-hadoop2.7.tgz\n",
    "# pip install pyspark findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0oCZtmWisavM"
   },
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "# update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ijvSQJAsezSX"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\"\n",
    "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "# os.environ[\"PYSPARK_SUBMIT_ARGS\"] =\"--master local[2] pyspark-shell\"\n",
    "\n",
    "# # Find Spark so that we can access session within our notebook\n",
    "# import findspark\n",
    "# findspark.init()\n",
    "\n",
    "# # Start SparkSession on all available cores\n",
    "# from pyspark.sql import SparkSession\n",
    "# spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9HkPEb7Dj7WG"
   },
   "outputs": [],
   "source": [
    "# ! pip install wget\n",
    "# import wget\n",
    "\n",
    "# # Download complaints data \n",
    "# wget.download('https://macs-30123-final-proj-tyagie.s3.amazonaws.com/complaints.parquet', 'complaints.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z2MIHJYkfq4p"
   },
   "outputs": [],
   "source": [
    "# DATA = 'complaints.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "obNgWxF6fzaY"
   },
   "source": [
    "### EMR Cluster Configuration\n",
    "If running on an EMR cluster, the PySpark configuration is already set up, but I have to install a few packages into the environment.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kx7b-Balf3Dv"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5801010a796047cfba76ffe7f9be4fb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>5</td><td>application_1591380815751_0006</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-66-63.ec2.internal:20888/proxy/application_1591380815751_0006/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-68-24.ec2.internal:8042/node/containerlogs/container_1591380815751_0006_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DATA = 's3://macs-30123-final-proj-tyagie/complaints.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf5a6f1acfc845fbb670d872fb698de0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datetime\n",
      "  Using cached https://files.pythonhosted.org/packages/73/22/a5297f3a1f92468cc737f8ce7ba6e5f245fcfafeae810ba37bd1039ea01c/DateTime-4.3-py2.py3-none-any.whl\n",
      "Collecting zope.interface (from datetime)\n",
      "  Using cached https://files.pythonhosted.org/packages/f3/21/8db61925409f4a4bac5fac19dbee26b735bd410b0f05f233058ace5511dc/zope.interface-5.1.0-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.7/site-packages (from datetime)\n",
      "Requirement already satisfied: setuptools in /mnt/tmp/1591401005139-0/lib/python3.7/site-packages (from zope.interface->datetime)\n",
      "Installing collected packages: zope.interface, datetime\n",
      "Successfully installed datetime-4.3 zope.interface-5.1.0"
     ]
    }
   ],
   "source": [
    "sc.install_pypi_package(\"datetime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "392bf3cf75fb407e8ba26ec53da27ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1r7lYjZu7bLW"
   },
   "source": [
    "### Load Data\n",
    "I first load the full CFPB Consumer Complaints Database. The original data is available from the [CFPB website](https://www.consumerfinance.gov/data-research/consumer-complaints/) under the Download the Data section. In the previous script `01_download-and-store.py`, I download this data in CSV format, then convert it to Parquet format and store it in an S3 bucket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "colab_type": "code",
    "id": "f_BBHkJze7AN",
    "outputId": "2c33e0d2-dae5-4127-8d2d-687cf5152b83"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7131d518bdcd4071b44ed0dd7c343550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "# Specify schema \n",
    "schema = StructType([\n",
    "    StructField(\"date_received\", StringType(), True),\n",
    "    StructField(\"product\", StringType(), True),\n",
    "    StructField(\"sub-product\", StringType(), True), \n",
    "    StructField(\"issue\", StringType(), True),\n",
    "    StructField(\"sub-issue\", StringType(), True),\n",
    "    StructField(\"consumer_complaint_narrative\", StringType(), True), \n",
    "    StructField(\"company_public_response\", StringType(), True),\n",
    "    StructField(\"company\", StringType(), True),\n",
    "    StructField(\"state\", StringType(), True),\n",
    "    StructField(\"zip_code\", StringType(), True), \n",
    "    StructField(\"tags\", StringType(), True),\n",
    "    StructField(\"consumer_consent_provided?\", StringType(), True),\n",
    "    StructField(\"submitted_via\", StringType(), True), \n",
    "    StructField(\"date_sent_to_company\", StringType(), True),\n",
    "    StructField(\"company_response_to_consumer\", StringType(), True),\n",
    "    StructField(\"timely_response?\", StringType(), True),\n",
    "    StructField(\"consumer_disputed?\", StringType(), True), \n",
    "    StructField(\"complaint_id\", StringType(), True),\n",
    "])\n",
    "\n",
    "# Load data \n",
    "data = spark.read.parquet(DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "h6ODJH6kVvNY",
    "outputId": "6b2e86f0-4bf5-413f-dbd8-427238695a72"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "917d9d33124d47659c7a93f7340f25d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Limit to data after 2013 (methodology change) and valid outcomes  \n",
    "YEARS = ['2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020']\n",
    "LABELS = ['Closed with explanation', \n",
    "          'Closed with monetary relief', \n",
    "          'Closed with non-monetary relief', \n",
    "          'Untimely response']\n",
    "\n",
    "data = data.withColumn('year', data['date_received'].substr(1, 4)) \n",
    "data = data.where(data.year.isin(YEARS))\n",
    "data = data.where(data.company_response_to_consumer.isin(LABELS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OzFQxohz8nKJ"
   },
   "source": [
    "### Generate Features and Label Vectors\n",
    "\n",
    "I created features from the categorical variables through one-hot-encoding the following variables: `product`, `issue`, `company`, `state`.\n",
    "I also encode the multi-class outcome that I'm predicting (`company_response_to_consumer`). Note that I specify a handler to skip rows in the testing data with one-hot-encoded feature values that weren't seen in the training data. I also encode (rather than drop) missing values, given that missing data in these fields may be itself predictive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M1ErV1CgQeP9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d46bed1cb01642babc4df00dc97fa663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoderEstimator, VectorAssembler \n",
    "\n",
    "# Replace missing values in categorical columns with 'Missing' string \n",
    "data = data.fillna({'product':'Missing', \n",
    "                    'issue': 'Missing', \n",
    "                    'state': 'Missing', \n",
    "                    'company': 'Missing', \n",
    "                    'consumer_complaint_narrative': ''})\n",
    "\n",
    "# Only encode companies with more than 1000 complaints \n",
    "w = Window.partitionBy('company')\n",
    "data = data.withColumn('company_complaints', F.count('company').over(w))\n",
    "data = data.withColumn('company_limited', \n",
    "                       when(data['company_complaints'] > 1000, data['company']).otherwise('Other'))\n",
    "\n",
    "# Encode categorical features \n",
    "product_indexer = StringIndexer(\n",
    "    inputCol='product', \n",
    "    outputCol='product_idx', \n",
    "    handleInvalid='skip'\n",
    ")\n",
    "product_onehot = OneHotEncoderEstimator(\n",
    "    inputCols=['product_idx'], \n",
    "    outputCols=['product_dummy']\n",
    ")\n",
    "\n",
    "issue_indexer = StringIndexer(\n",
    "    inputCol='issue', \n",
    "    outputCol='issue_idx', \n",
    "    handleInvalid='skip'\n",
    ")\n",
    "issue_onehot = OneHotEncoderEstimator(\n",
    "    inputCols=['issue_idx'], \n",
    "    outputCols=['issue_dummy']\n",
    ")\n",
    "\n",
    "state_indexer = StringIndexer(\n",
    "    inputCol='state', \n",
    "    outputCol='state_idx', \n",
    "    handleInvalid='skip'\n",
    ")\n",
    "state_onehot = OneHotEncoderEstimator(\n",
    "    inputCols=['state_idx'], \n",
    "    outputCols=['state_dummy']\n",
    ")\n",
    "\n",
    "company_indexer = StringIndexer(\n",
    "    inputCol='company', \n",
    "    outputCol='company_idx', \n",
    "    handleInvalid='skip'\n",
    ")\n",
    "company_onehot = OneHotEncoderEstimator(\n",
    "    inputCols=['company_idx'], \n",
    "    outputCols=['company_dummy']\n",
    ")\n",
    "\n",
    "# Assemble features \n",
    "assembler = VectorAssembler(\n",
    "    inputCols=['product_dummy', 'issue_dummy', 'state_dummy', 'company_dummy'], \n",
    "    outputCol='features'\n",
    ")\n",
    "\n",
    "# Encode label \n",
    "label_indexer = StringIndexer(\n",
    "    inputCol='company_response_to_consumer', \n",
    "    outputCol='label'\n",
    ")\n",
    "\n",
    "data = data.na.drop(subset=['company_response_to_consumer'])\n",
    "data = label_indexer.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N4eS-PB9_0He"
   },
   "source": [
    "### Resample Data\n",
    "To address the class imbalance in this data (where over 80% of complaints result in Closed with explanation outcomes), I over-sample the minority classes and under-sample the majority class in the training data. I do this using standard bootstrapping, but I also provide code to do this using synthetic resampling of the minority classes. Note that this requires converting the PySpark RDDs into NumPy arrays or Pandas dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZJtKydl1oFRh"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4194bcf1a9b94d6abbe0f8645dd2f109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split into training and testing data \n",
    "train_df, test_df = data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "I8xDKuijjyX-",
    "outputId": "033dfaba-f966-4cb2-afcb-7d2998889c73"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d43e215b756480c903d93b0ad8b8503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from functools import reduce\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "FRAC_MAJORITY = 0.5 \n",
    "\n",
    "# Resample (undersample majority class, undersample majority class)\n",
    "train_0 = train_df.where(col('label')==0.0).sample(True, FRAC_MAJORITY,  seed=0)\n",
    "frac_1 = train_0.count() / train_df.where(col('label')==1.0).count() \n",
    "frac_2 = train_0.count() / train_df.where(col('label')==2.0).count() \n",
    "frac_3 = train_0.count() / train_df.where(col('label')==3.0).count()\n",
    "\n",
    "train_0 = train_df.where(col('label')==0.0).sample(True, FRAC_MAJORITY,  seed=0)\n",
    "train_1 = train_df.where(col('label')==1.0).sample(True, frac_1, seed=0)\n",
    "train_2 = train_df.where(col('label')==2.0).sample(True, frac_2, seed=0)\n",
    "train_3 = train_df.where(col('label')==3.0).sample(True, frac_3, seed=0)\n",
    "\n",
    "train_dfs = [train_0, train_1, train_2, train_3]\n",
    "train_df_resampled = reduce(DataFrame.unionAll, train_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PEYCIBfg5zHP"
   },
   "outputs": [],
   "source": [
    "# Use synthetic oversampling - Note: no good PySpark implementations \n",
    "# e.g. https://github.com/anathan90/SparkSMOTE, https://github.com/Angkirat/Smote-for-Spark both are issue-prone \n",
    "\n",
    "# from imblearn.over_sampling import SMOTE \n",
    "\n",
    "# train_X = train_df.select('product_dummy', 'issue_dummy', 'state_dummy', 'company_dummy').toPandas()\n",
    "# train_y = train_df.select('label').toPandas()\n",
    "\n",
    "# sm = SMOTE(random_state=0) \n",
    "# train_X_resampled, train_y_resampled = sm.fit_sample(train_X, train_y)\n",
    "# train_pdf_resampled = pd.concat(train_X_resampled, train_y_resampled)\n",
    "\n",
    "# train_df_resampled = spark.createDataFrame(train_pdf_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wv_WNFVXboJB"
   },
   "source": [
    "### Train Models \n",
    "Finally, I build my machine learning models. I use k-fold cross-validation to identify the best performing model across a variety of classifier and hyperparameter specifications. I build the following types of classifiers: Logistic Regression, Decision Tree, Naive Bayes, Gradient-Boosted Trees, and Support Vector Machines. I iterate over (admittedly small - running out of AWS credits!) parameter grids. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P0paqbC5bhYp"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46953bac0a024c6396bd881362bf8fbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "from pyspark.ml.classification import OneVsRest\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# Build feature engineering pipeline  \n",
    "pipeline = Pipeline(\n",
    "    stages=[product_indexer, product_onehot, \n",
    "            issue_indexer, issue_onehot, \n",
    "            state_indexer, state_onehot,  \n",
    "            company_indexer, company_onehot, \n",
    "            assembler]\n",
    ")\n",
    "\n",
    "# Fit feature engineering pipeline \n",
    "fitPipeline = pipeline.fit(train_df_resampled)\n",
    "train_fit = fitPipeline.transform(train_df_resampled)\n",
    "test_fit = fitPipeline.transform(test_df)\n",
    "\n",
    "# Create evaluator \n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol='label'\n",
    ")\n",
    "\n",
    "# k in k-fold cross validation \n",
    "NUM_FOLDS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eFNqZJRDyGy3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1572925d49114bedb7ba66a967f224b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Elapsed: 0:05:19.786501\n",
      "f1 0.62054165014387\n",
      "regParam: regularization parameter (>= 0) (default: 0.0, current: 0.1)"
     ]
    }
   ],
   "source": [
    "# LOGISTIC REGRESSION  \n",
    "lr = LogisticRegression(labelCol='label')\n",
    "ovr = OneVsRest(classifier=lr)\n",
    "\n",
    "paramGrid = ((ParamGridBuilder()\n",
    "  .addGrid(ovr.regParam, [0.1, 1.0]) \n",
    "  .build()))\n",
    "\n",
    "cv = CrossValidator(estimator=ovr, \n",
    "                    estimatorParamMaps=paramGrid, \n",
    "                    evaluator=evaluator, \n",
    "                    numFolds=NUM_FOLDS)\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "model = cv.fit(train_fit)\n",
    "print(\"Time Elapsed:\", datetime.datetime.now() - start)\n",
    "\n",
    "predictions = model.transform(test_fit)\n",
    "print(evaluator.getMetricName(), evaluator.evaluate(predictions))\n",
    "print(model.bestModel.explainParam('regParam'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6759c480b11402db35284d68bb63a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Elapsed: 1:00:15.282377\n",
      "f1 0.47619958830219755\n",
      "impurity: Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini (default: gini, current: gini)\n",
      "maxDepth: Maximum depth of the tree. (Nonnegative) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. (default: 5, current: 20)"
     ]
    }
   ],
   "source": [
    "# DECISION TREE \n",
    "dt = DecisionTreeClassifier(labelCol='label')\n",
    "ovr = OneVsRest(classifier=dt)\n",
    "\n",
    "paramGrid = ((ParamGridBuilder()\n",
    "  .addGrid(ovr.impurity, ['gini', 'entropy'])\n",
    "  .addGrid(ovr.maxDepth, [10, 20])            \n",
    "  .build()))\n",
    "\n",
    "cv = CrossValidator(estimator=ovr, \n",
    "                    estimatorParamMaps=paramGrid, \n",
    "                    evaluator=evaluator, \n",
    "                    numFolds=NUM_FOLDS)\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "model = cv.fit(train_fit)\n",
    "print(\"Time Elapsed:\", datetime.datetime.now() - start)\n",
    "\n",
    "predictions = model.transform(test_fit)\n",
    "print(evaluator.getMetricName(), evaluator.evaluate(predictions))\n",
    "print(model.bestModel.explainParam('impurity'))\n",
    "print(model.bestModel.explainParam('maxDepth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aa212d9ba324d79bd4291bf71f9beea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Elapsed: 0:01:36.720193\n",
      "f1 0.5051995904019904"
     ]
    }
   ],
   "source": [
    "# NAIVE BAYES \n",
    "nb = NaiveBayes(labelCol='label')\n",
    "ovr = OneVsRest(classifier=nb)\n",
    "\n",
    "paramGrid = ((ParamGridBuilder()       \n",
    "  .build()))\n",
    "\n",
    "cv = CrossValidator(estimator=ovr, \n",
    "                    estimatorParamMaps=paramGrid, \n",
    "                    evaluator=evaluator, \n",
    "                    numFolds=NUM_FOLDS)\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "model = cv.fit(train_fit)\n",
    "print(\"Time Elapsed:\", datetime.datetime.now() - start)\n",
    "\n",
    "predictions = model.transform(test_fit)\n",
    "print(evaluator.getMetricName(), evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient-Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GRADIENT BOOSTED TREES \n",
    "# NOTE: PySpark's OVR support for Gradient Boosted Trees is glitchy \n",
    "# https://github.com/eubr-bigsea/citrus/issues/82\n",
    "\n",
    "# gbt = GBTClassifier(labelCol='label')\n",
    "# ovr = OneVsRest(classifier=gbt)\n",
    "\n",
    "# paramGrid = ((ParamGridBuilder()\n",
    "#   .addGrid(gbt.stepSize, [0.01, 0.1, 0.5])\n",
    "#   .addGrid(gbt.maxDepth, [10, 20])            \n",
    "#   .build()))\n",
    "\n",
    "# cv = CrossValidator(estimator=ovr, \n",
    "#                     estimatorParamMaps=paramGrid, \n",
    "#                     evaluator=evaluator, \n",
    "#                     numFolds=NUM_FOLDS)\n",
    "\n",
    "# start = datetime.datetime.now()\n",
    "# model = cv.fit(train_fit)\n",
    "# print(\"Time Elapsed:\", datetime.datetime.now() - start)\n",
    "\n",
    "# predictions = model.transform(test_fit)\n",
    "# print(evaluator.getMetricName(), evaluator.evaluate(predictions))\n",
    "# print(model.bestModel.explainParam('stepSize'))\n",
    "# print(model.bestModel.explainParam('maxDepth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v1wGZx9T2-24"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69f4bef74c2c4f3fbe6313bcc0f68f8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread cell_monitor-15:\n",
      "Traceback (most recent call last):\n",
      "  File \"/emr/notebook-env/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/emr/notebook-env/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/emr/notebook-env/lib/python3.7/site-packages/awseditorssparkmonitoringwidget-1.0-py3.7.egg/awseditorssparkmonitoringwidget/cellmonitor.py\", line 178, in cell_monitor\n",
      "    job_binned_stages[job_id][stage_id] = all_stages[stage_id]\n",
      "KeyError: 9195\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Elapsed: 0:56:18.537995\n",
      "f1 0.581622630251788"
     ]
    }
   ],
   "source": [
    "# SUPPORT VECTOR MACHINE \n",
    "# ovr = LinearSVC(labelCol='label')\n",
    "svm = LinearSVC(labelCol='label')\n",
    "ovr = OneVsRest(classifier=svm)\n",
    "\n",
    "paramGrid = ((ParamGridBuilder()\n",
    "  .addGrid(svm.regParam, [0.1])\n",
    "  .build()))\n",
    "\n",
    "cv = CrossValidator(estimator=ovr, \n",
    "                    estimatorParamMaps=paramGrid, \n",
    "                    evaluator=evaluator, \n",
    "                    numFolds=NUM_FOLDS)\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "model = cv.fit(train_fit)\n",
    "print(\"Time Elapsed:\", datetime.datetime.now() - start)\n",
    "\n",
    "predictions = model.transform(test_fit)\n",
    "print(evaluator.getMetricName(), evaluator.evaluate(predictions))\n",
    "# print(model.bestModel.explainParam('stepSize'))\n",
    "# print(model.bestModel.explainParam('maxDepth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x9sPIvRL9Ohv"
   },
   "source": [
    "### Evaluate Models\n",
    "Finally, I provide a more substantive evaluation of the best performing model. I report precision, recall, and F1 score overall unweighted, by class, and weighted by class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "Uv6qBYPZacYh",
    "outputId": "0bb1c749-c18d-4665-9ea2-5cb67b5f4b31"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d554f4749946839962d5b5a72346c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "# Instantiate metrics object\n",
    "predictionAndLabels = predictions.select('prediction', 'label')\n",
    "metrics = MulticlassMetrics(predictionAndLabels.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 82
    },
    "colab_type": "code",
    "id": "XNLT6DZo6x8c",
    "outputId": "88c53cf6-485b-47a5-82ac-9cff41a999d5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "576d043a42944776a3f1f53190ed5ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Summary Stats\n",
      "  Precision = 0.5255003155142883\n",
      "  Recall = 0.5255003155142883\n",
      "  F1 score = 0.5255003155142883"
     ]
    }
   ],
   "source": [
    "# Overall statistics\n",
    "print(\"Overall Summary Stats\")\n",
    "print(\"  Precision = %s\" % metrics.precision())\n",
    "print(\"  Recall = %s\" % metrics.recall())\n",
    "print(\"  F1 score = %s\" % metrics.fMeasure())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "id": "VFR1-s1S9UIT",
    "outputId": "15f2e786-6485-4dba-d340-ff2d6ffbbd1e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "944d8f09a49540309ca300e55bd62447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics by Class\n",
      "  Class 1.0\n",
      "   Precision = 0.2902257271017219\n",
      "   Recall = 0.6846147282191313\n",
      "   F1 score = 0.407641693976577\n",
      "  Class 2.0\n",
      "   Precision = 0.177631857657276\n",
      "   Recall = 0.8992065194081064\n",
      "   F1 score = 0.29666053488043015\n",
      "  Class 0.0\n",
      "   Precision = 0.9483585084443453\n",
      "   Recall = 0.4728680016119395\n",
      "   F1 score = 0.6310723723862951\n",
      "  Class 3.0\n",
      "   Precision = 0.24178549287042778\n",
      "   Recall = 0.9774436090225563\n",
      "   F1 score = 0.3876739562624254"
     ]
    }
   ],
   "source": [
    "# Statistics by class \n",
    "labels = predictions.select('label').distinct().collect()\n",
    "print(\"Summary Statistics by Class\")\n",
    "for l in labels: \n",
    "  print(\"  Class %s\" % l[0])\n",
    "  print(\"   Precision = %s\" % metrics.precision(l[0]))\n",
    "  print(\"   Recall = %s\" % metrics.recall(l[0]))\n",
    "  print(\"   F1 score = %s\" % metrics.fMeasure(l[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 82
    },
    "colab_type": "code",
    "id": "-vazU5NNsj3o",
    "outputId": "aa57110e-dca1-4383-9a0b-431357fc03e2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "480e97d5eaa14a2eb206f9093292dc10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Summary Stats\n",
      "  Weighted Recall = 0.5255003155142883\n",
      "  Weighted precision = 0.8177752682209127\n",
      "  Weighted F1 score = 0.5829016511363316"
     ]
    }
   ],
   "source": [
    "# Weighted summary statistics \n",
    "print(\"Weighted Summary Stats\")\n",
    "print(\"  Weighted Recall = %s\" % metrics.weightedRecall)\n",
    "print(\"  Weighted precision = %s\" % metrics.weightedPrecision)\n",
    "print(\"  Weighted F1 score = %s\" % metrics.weightedFMeasure())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "03_Build Models.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
